\addcontentsline{toc}{chapter}{Abstract}

\begin{abstract}

A recent trend in the field of neuroimaging is towards data sharing and large scale experiments~\citep{van2012human,goldberger2000physiobank}. This has opened up many interesting opportunities with respect to applying machine learning but at the same time poses challenges with respect to automatically preprocessing the data.

In this report, an automated solution for detecting bad trials in magneto-/electroencephalography (M/EEG) is presented. Bad trials are commonly identified using peak-to-peak rejection thresholds that are set manually. This work proposes a solution to determine them automatically using cross-validation. We show that automatically selected rejection thresholds perform at par with manual thresholds, which can save hours of visual data inspection. We then use this automated approach to learn a sensor-specific rejection threshold. Finally, we use this approach to remove trials with finer precision and/or partially repair them using interpolation. The performance is illustrated on three public datasets. The method clearly performs better than a competitive benchmark on a 19-subject Faces dataset. 

Next, future work is outlined, which will involve dictionary learning for M/EEG.  Important developmental milestones in the literature with respect to building time-invariant and physically informed models are described. The atoms will be learned in an unsupervised manner. Key novelties in this work will involve learning efficient representations at large scale.
\end{abstract}
